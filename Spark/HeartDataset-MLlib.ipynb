{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on 'HEART DISEASE' Dataset  \n",
    "Elif Cansu YILDIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler, MinMaxScaler, IndexToString\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"MachineLearningExample\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used is 'Heart Disease' dataset from Kaggle. You can get from this [link](https://www.kaggle.com/ronitf/heart-disease-uci)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- cp: integer (nullable = true)\n",
      " |-- trestbps: integer (nullable = true)\n",
      " |-- chol: integer (nullable = true)\n",
      " |-- fbs: integer (nullable = true)\n",
      " |-- restecg: integer (nullable = true)\n",
      " |-- thalach: integer (nullable = true)\n",
      " |-- exang: integer (nullable = true)\n",
      " |-- oldpeak: double (nullable = true)\n",
      " |-- slope: integer (nullable = true)\n",
      " |-- ca: integer (nullable = true)\n",
      " |-- thal: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      "\n",
      "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
      "|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
      "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
      "| 63|  1|  3|     145| 233|  1|      0|    150|    0|    2.3|    0|  0|   1|     1|\n",
      "| 37|  1|  2|     130| 250|  0|      1|    187|    0|    3.5|    0|  0|   2|     1|\n",
      "| 41|  0|  1|     130| 204|  0|      0|    172|    0|    1.4|    2|  0|   2|     1|\n",
      "| 56|  1|  1|     120| 236|  0|      1|    178|    0|    0.8|    2|  0|   2|     1|\n",
      "| 57|  0|  0|     120| 354|  0|      1|    163|    1|    0.6|    2|  0|   2|     1|\n",
      "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('datasets/heart.csv', header = True, inferSchema = True)  #Kaggle Dataset\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__HOW MANY DISTINCT VALUE DO COLUMNS HAVE?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
      "|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
      "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
      "| 41|  2|  4|      49| 152|  2|      3|     91|    2|     40|    3|  5|   4|     2|\n",
      "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(*(countDistinct(col(c)).alias(c) for c in df.columns)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SET the Label Column and Input Columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelColumn = \"thal\"\n",
    "input_columns = [t[0] for t in df.dtypes if t[0]!=labelColumn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data count:  303\n",
      "train data count:  218\n",
      "test data count:  85\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "print(\"total data count: \", df.count())\n",
    "print(\"train data count: \", trainingData.count())\n",
    "print(\"test data count: \", testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TRAINING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = input_columns, outputCol='features')\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol=labelColumn,\n",
    "                        maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "stages = [assembler, lr]\n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "model = partialPipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__MAKE PREDICTIONS__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+----------+-----+\n",
      "|probability                                                                     |prediction|label|\n",
      "+--------------------------------------------------------------------------------+----------+-----+\n",
      "|[0.011082788245690223,0.05729867172540959,0.5740584251416755,0.3575601148872248]|2.0       |2    |\n",
      "|[0.011082788245690223,0.05729867172540959,0.5740584251416755,0.3575601148872248]|2.0       |3    |\n",
      "|[0.011082788245690223,0.05729867172540959,0.5740584251416755,0.3575601148872248]|2.0       |2    |\n",
      "|[0.011082788245690223,0.05729867172540959,0.5740584251416755,0.3575601148872248]|2.0       |2    |\n",
      "|[0.012875234771605678,0.06656572644096996,0.5051698495258184,0.4153891892616059]|2.0       |3    |\n",
      "+--------------------------------------------------------------------------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "\n",
    "predictionss = predictions.select(\"probability\", \"rawPrediction\", \"prediction\", \n",
    "                                 col(labelColumn).alias(\"label\"))\n",
    "predictionss[[\"probability\", \"prediction\", \"label\"]].show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EVALUATION for Binary Classification__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "areaUnderROC = evaluator.evaluate(predictionss)\n",
    "print(\"Area under ROC = %g\" % areaUnderROC)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderPR\")\n",
    "areaUnderPR = evaluator.evaluate(predictionss)\n",
    "print(\"areaUnderPR = %g\" % areaUnderPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EVALUATION for Multiclass Classification__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.564706\n",
      "f1 = 0.407607\n",
      "weightedPrecision = 0.318893\n",
      "weightedRecall = 0.564706\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictionss)\n",
    "print(\"accuracy = %g\" % accuracy)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(predictionss)\n",
    "print(\"f1 = %g\" % f1)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "weightedPrecision = evaluator.evaluate(predictionss)\n",
    "print(\"weightedPrecision = %g\" % weightedPrecision)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "weightedRecall = evaluator.evaluate(predictionss)\n",
    "print(\"weightedRecall = %g\" % weightedRecall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
