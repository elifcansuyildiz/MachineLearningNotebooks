{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK MACHINE LEARNING LIBRARY  \n",
    "ELIF CANSU YILDIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, IndexToString\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, DecisionTreeClassifier, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    " .builder\\\n",
    " .appName(\"MLLib-Algorithms\")\\\n",
    " .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EXAMPLE DATA SET FROM KAGGLE:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- deposit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('bank.csv', header = True, inferSchema = True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical col: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'deposit']\n",
      "+----------+-------+---------+-------+-------+----+-------+-----+--------+-------+\n",
      "|       job|marital|education|default|housing|loan|contact|month|poutcome|deposit|\n",
      "+----------+-------+---------+-------+-------+----+-------+-----+--------+-------+\n",
      "|    admin.|married|secondary|     no|    yes|  no|unknown|  may| unknown|    yes|\n",
      "|    admin.|married|secondary|     no|     no|  no|unknown|  may| unknown|    yes|\n",
      "|technician|married|secondary|     no|    yes|  no|unknown|  may| unknown|    yes|\n",
      "|  services|married|secondary|     no|    yes|  no|unknown|  may| unknown|    yes|\n",
      "|    admin.|married| tertiary|     no|     no|  no|unknown|  may| unknown|    yes|\n",
      "+----------+-------+---------+-------+-------+----+-------+-----+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+-------+---+--------+--------+-----+--------+\n",
      "|age|balance|day|duration|campaign|pdays|previous|\n",
      "+---+-------+---+--------+--------+-----+--------+\n",
      "| 59|   2343|  5|    1042|       1|   -1|       0|\n",
      "| 56|     45|  5|    1467|       1|   -1|       0|\n",
      "| 41|   1270|  5|    1389|       1|   -1|       0|\n",
      "| 55|   2476|  5|     579|       1|   -1|       0|\n",
      "| 54|    184|  5|     673|       2|   -1|       0|\n",
      "+---+-------+---+--------+--------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#numeric_features = [t[0] for t in df.dtypes if t[1] == 'double']\n",
    "categorical_features = [t[0] for t in df.dtypes if t[1]=='string']\n",
    "print(\"categorical col:\", categorical_features)\n",
    "df.select(categorical_features).show(5)\n",
    "\n",
    "numeric_features = [t[0] for t in df.dtypes if t[1]=='int']\n",
    "df.select(numeric_features).show(5)\n",
    "#df[numeric_features].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__HOW MANY DISTINCT VALUE DO COLUMNS HAVE?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+--------+-----+--------+\n",
      "|age|balance|day|duration|campaign|pdays|previous|\n",
      "+---+-------+---+--------+--------+-----+--------+\n",
      "| 76|   3805| 31|    1428|      36|  472|      34|\n",
      "+---+-------+---+--------+--------+-----+--------+\n",
      "\n",
      "+---+-------+---------+-------+-------+----+-------+-----+--------+-------+\n",
      "|job|marital|education|default|housing|loan|contact|month|poutcome|deposit|\n",
      "+---+-------+---------+-------+-------+----+-------+-----+--------+-------+\n",
      "| 12|      3|        4|      2|      2|   2|      3|   12|       4|      2|\n",
      "+---+-------+---------+-------+-------+----+-------+-----+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, countDistinct\n",
    "\n",
    "df.agg(*(countDistinct(col(c)).alias(c) for c in numeric_features)).show()\n",
    "df.agg(*(countDistinct(col(c)).alias(c) for c in categorical_features)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------- CLASSIFICATION ----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data count:  11162\n",
      "train data count:  7800\n",
      "test data count:  3362\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "print(\"total data count: \", df.count())\n",
    "print(\"train data count: \", trainingData.count())\n",
    "print(\"test data count: \", testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TRAINING__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: __fit()__ should be used with __StringIndexer()__ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol = 'housing', outputCol='indexedLabel',\n",
    "                             handleInvalid=\"error\", stringOrderType=\"frequencyDesc\")\\\n",
    "                            .fit(trainingData)\n",
    "\n",
    "assembler = VectorAssembler(inputCols = numeric_features, outputCol='features')\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol=\"indexedLabel\",\n",
    "                        maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "labelConverter = IndexToString(inputCol= \"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "stages = [assembler,labelIndexer, lr, labelConverter]\n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "model = partialPipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__MAKE PREDICTIONS__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+------------+----------+--------------+-----+\n",
      "|features                             |indexedLabel|prediction|predictedLabel|label|\n",
      "+-------------------------------------+------------+----------+--------------+-----+\n",
      "|[19.0,108.0,9.0,273.0,2.0,182.0,1.0] |0.0         |0.0       |no            |no   |\n",
      "|[20.0,292.0,5.0,385.0,2.0,93.0,1.0]  |0.0         |0.0       |no            |no   |\n",
      "|[20.0,0.0,1.0,143.0,5.0,91.0,8.0]    |0.0         |0.0       |no            |no   |\n",
      "|[20.0,6991.0,12.0,178.0,2.0,-1.0,0.0]|0.0         |0.0       |no            |no   |\n",
      "|[20.0,130.0,4.0,75.0,3.0,-1.0,0.0]   |0.0         |0.0       |no            |no   |\n",
      "+-------------------------------------+------------+----------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "predictions = predictions.select(\"features\", \"indexedLabel\", \"prediction\", \"predictedLabel\",\n",
    "                                 col(\"housing\").alias(\"label\"))\n",
    "predictions.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EVALUATION__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.5\n",
      "areaUnderPR = 0.463415\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"indexedLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "areaUnderROC = evaluator.evaluate(predictions)\n",
    "print(\"Area under ROC = %g\" % areaUnderROC)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"indexedLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderPR\")\n",
    "areaUnderPR = evaluator.evaluate(predictions)\n",
    "print(\"areaUnderPR = %g\" % areaUnderPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "labelIndexer = StringIndexer(inputCol = 'housing', outputCol='indexedLabel',\n",
    "                             handleInvalid=\"error\", stringOrderType=\"frequencyDesc\").fit(data)\n",
    "\n",
    "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "assembler = VectorAssembler(inputCols = numeric_features, outputCol='features')\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "labelConverter = IndexToString(inputCol= \"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "stages = [assembler,labelIndexer, rf, labelConverter]\n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "model = partialPipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+--------------+-----+\n",
      "|            features|indexedLabel|prediction|predictedLabel|label|\n",
      "+--------------------+------------+----------+--------------+-----+\n",
      "|[18.0,608.0,13.0,...|         0.0|       0.0|            no|   no|\n",
      "|[18.0,108.0,9.0,9...|         0.0|       0.0|            no|   no|\n",
      "|[19.0,608.0,12.0,...|         0.0|       0.0|            no|   no|\n",
      "|[19.0,779.0,1.0,1...|         0.0|       0.0|            no|   no|\n",
      "|[20.0,336.0,5.0,1...|         0.0|       0.0|            no|   no|\n",
      "+--------------------+------------+----------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "predictions = predictions.select(\"features\", \"indexedLabel\", \"prediction\", \"predictedLabel\",\n",
    "                                 col(\"housing\").alias(\"label\"))\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.626502\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_b1960f89c5b3) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator2.evaluate(predictions)\n",
    "print(\"accuracy = %g\" % accuracy)\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADIENT-BOOSTED TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "labelIndexer = StringIndexer(inputCol = 'housing', outputCol='indexedLabel',\n",
    "                             handleInvalid=\"error\", stringOrderType=\"frequencyDesc\").fit(data)\n",
    "\n",
    "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "assembler = VectorAssembler(inputCols = numeric_features, outputCol='features')\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "labelConverter = IndexToString(inputCol= \"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "stages = [assembler,labelIndexer, gbt, labelConverter]\n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "model = partialPipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+--------------+-----+\n",
      "|            features|indexedLabel|prediction|predictedLabel|label|\n",
      "+--------------------+------------+----------+--------------+-----+\n",
      "|[18.0,608.0,12.0,...|         0.0|       0.0|            no|   no|\n",
      "|[18.0,5.0,24.0,14...|         0.0|       0.0|            no|   no|\n",
      "|[18.0,108.0,8.0,1...|         0.0|       0.0|            no|   no|\n",
      "|[19.0,103.0,10.0,...|         0.0|       0.0|            no|   no|\n",
      "|[19.0,302.0,16.0,...|         0.0|       0.0|            no|   no|\n",
      "+--------------------+------------+----------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "predictions = predictions.select(\"features\", \"indexedLabel\", \"prediction\", \"predictedLabel\",\n",
    "                                 col(\"housing\").alias(\"label\"))\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.641452\n",
      "GBTClassificationModel (uid=GBTClassifier_d48295992724) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"accuracy = %g\" % accuracy)\n",
    "\n",
    "gbtModel = model.stages[2]\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "labelIndexer = StringIndexer(inputCol = 'housing', outputCol='indexedLabel',\n",
    "                             handleInvalid=\"error\", stringOrderType=\"frequencyDesc\").fit(data)\n",
    "\n",
    "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "assembler = VectorAssembler(inputCols = numeric_features, outputCol='features')\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\")\n",
    "\n",
    "labelConverter = IndexToString(inputCol= \"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "stages = [assembler,labelIndexer, dt, labelConverter]\n",
    "partialPipeline = Pipeline().setStages(stages)\n",
    "treeModel = partialPipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+--------------+-----+\n",
      "|            features|indexedLabel|prediction|predictedLabel|label|\n",
      "+--------------------+------------+----------+--------------+-----+\n",
      "|[18.0,5.0,24.0,14...|         0.0|       0.0|            no|   no|\n",
      "|[19.0,55.0,6.0,89...|         0.0|       0.0|            no|   no|\n",
      "|[19.0,302.0,16.0,...|         0.0|       0.0|            no|   no|\n",
      "|[19.0,108.0,9.0,2...|         0.0|       0.0|            no|   no|\n",
      "|[19.0,779.0,1.0,1...|         0.0|       0.0|            no|   no|\n",
      "+--------------------+------------+----------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = treeModel.transform(testData)\n",
    "predictions = predictions.select(\"features\", \"indexedLabel\", \"prediction\", \"predictedLabel\",\n",
    "                                 col(\"housing\").alias(\"label\"))\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.588875\n",
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_009cad06afd3) of depth 5 with 27 nodes\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"accuracy = %g\" % accuracy)\n",
    "\n",
    "dtModel = treeModel.stages[2]\n",
    "print(dtModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTI LAYER PERCEPTRON CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol='housing', outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "splits = data.randomSplit([0.6,0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify layers for the neural network:  \n",
    "Input layer of size 7 (features), two intermediate of size 5 and 4  \n",
    "And output of size 2 (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=numeric_features, outputCol=\"features\")\n",
    "\n",
    "layers = [7, 5, 4, 2]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter= 500, layers=layers, blockSize=128, seed=1234,\n",
    "                                         featuresCol='features' , labelCol = \"indexedLabel\")\n",
    "\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n",
    "\n",
    "partialPipeline = Pipeline(stages=[labelIndexer, assembler, trainer, labelConverter])\n",
    "model = partialPipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+--------------+-----+\n",
      "|            features|indexedLabel|prediction|predictedLabel|label|\n",
      "+--------------------+------------+----------+--------------+-----+\n",
      "|[18.0,608.0,12.0,...|         0.0|       0.0|            no|   no|\n",
      "|[18.0,608.0,13.0,...|         0.0|       0.0|            no|   no|\n",
      "|[18.0,5.0,24.0,14...|         0.0|       0.0|            no|   no|\n",
      "|[18.0,348.0,5.0,4...|         0.0|       0.0|            no|   no|\n",
      "|[19.0,103.0,10.0,...|         0.0|       0.0|            no|   no|\n",
      "+--------------------+------------+----------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions = predictions.select(\"features\", \"indexedLabel\", \"prediction\", \"predictedLabel\",\n",
    "                                 col(\"housing\").alias(\"label\"))\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.561494\n",
      "MultilayerPerceptronClassifier_e512e4399148\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"accuracy = %g\" % accuracy)\n",
    "\n",
    "perceptronModel = model.stages[2]\n",
    "print(perceptronModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DATA SHOW WITH SOME FUNCTIONS__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+---------+-------+\n",
      "|age|       job|marital|education|default|\n",
      "+---+----------+-------+---------+-------+\n",
      "| 59|    admin.|married|secondary|     no|\n",
      "| 56|    admin.|married|secondary|     no|\n",
      "| 41|technician|married|secondary|     no|\n",
      "| 55|  services|married|secondary|     no|\n",
      "| 54|    admin.|married| tertiary|     no|\n",
      "+---+----------+-------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|          duration|\n",
      "+-------+------------------+\n",
      "|  count|             11162|\n",
      "|   mean|371.99381831213043|\n",
      "| stddev|347.12838571630687|\n",
      "|    min|                 2|\n",
      "|    max|              3881|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+\n",
      "|marital|\n",
      "+-------+\n",
      "|married|\n",
      "|married|\n",
      "|married|\n",
      "|married|\n",
      "|married|\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "['age', 'job', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit']\n",
      "['age', 'job', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit']\n"
     ]
    }
   ],
   "source": [
    "df.count()\n",
    "len(df.columns)\n",
    "data[data.columns[:5]].show(5)\n",
    "data.describe(['duration']).show(5)\n",
    "\n",
    "data[['marital']].show(5)\n",
    "\n",
    "columnss = data.columns[:2] + data.columns[3:]\n",
    "print(columnss)\n",
    "\n",
    "label = ['marital']\n",
    "features = data.select([column for column in data.columns if column not in label])\n",
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------CLUSTERING--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------+-------+-------------------------------------+\n",
      "|pdays|previous|poutcome|deposit|features                             |\n",
      "+-----+--------+--------+-------+-------------------------------------+\n",
      "|-1   |0       |unknown |yes    |[59.0,2343.0,5.0,1042.0,1.0,-1.0,0.0]|\n",
      "|-1   |0       |unknown |yes    |[56.0,45.0,5.0,1467.0,1.0,-1.0,0.0]  |\n",
      "|-1   |0       |unknown |yes    |[41.0,1270.0,5.0,1389.0,1.0,-1.0,0.0]|\n",
      "|-1   |0       |unknown |yes    |[55.0,2476.0,5.0,579.0,1.0,-1.0,0.0] |\n",
      "|-1   |0       |unknown |yes    |[54.0,184.0,5.0,673.0,2.0,-1.0,0.0]  |\n",
      "+-----+--------+--------+-------+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = df\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numeric_features, outputCol=\"features\")\n",
    "\n",
    "partialPipeline = Pipeline(stages=[assembler])\n",
    "\n",
    "model = partialPipeline.fit(data)\n",
    "\n",
    "newdata = model.transform(data)\n",
    "newdata[newdata.columns[-5:]].show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeansModel(df, k=3 , inputCol=\"features\"):\n",
    "    \n",
    "    kmeans = KMeans(featuresCol=inputCol, k=k, seed=1, distanceMeasure=\"euclidean\")\n",
    "\n",
    "    model = kmeans.fit(df)\n",
    "\n",
    "    # Evaluate clustering by computing Within Set Sum of Squared Errors.\n",
    "    wssse = model.computeCost(df)\n",
    "    print(\"--------------------Within Set Sum of Squared Errors = \" + str(wssse))\n",
    "\n",
    "    # Shows the result.\n",
    "    \"\"\"centers = model.clusterCenters()\n",
    "    print(\"Cluster Centers: \")\n",
    "    for center in centers:\n",
    "        print(center)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  3 ----------------\n",
      "--------------------Within Set Sum of Squared Errors = 31776910042.39926\n",
      "i =  4 ----------------\n",
      "--------------------Within Set Sum of Squared Errors = 20961544898.84958\n",
      "i =  5 ----------------\n",
      "--------------------Within Set Sum of Squared Errors = 12491087263.526875\n",
      "i =  6 ----------------\n",
      "--------------------Within Set Sum of Squared Errors = 9388949070.739447\n",
      "i =  7 ----------------\n",
      "--------------------Within Set Sum of Squared Errors = 7716547135.553156\n",
      "i =  8 ----------------\n",
      "--------------------Within Set Sum of Squared Errors = 6705593727.66295\n",
      "i =  9 ----------------\n",
      "--------------------Within Set Sum of Squared Errors = 6137406183.470572\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,10):\n",
    "    print(\"i = \", i, \"----------------\")\n",
    "    kmeansModel(newdata, i, \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOME EXAMPLES USING SPARK DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "training.printSchema()\n",
    "#training.show(2, truncate=False)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"\\nCoefficients: \" + str(lrModel.coefficients))\n",
    "print(\"\\nIntercept: \" + str(lrModel.intercept))\n",
    "\n",
    "# We can also use the multinomial family for binary classification\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "mlrModel = mlr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"\\nMultinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"\\nMultinomial intercepts: \" + str(mlrModel.interceptVector))\n",
    "\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"\\nobjectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "lr.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------+\n",
      "|label|features                 |\n",
      "+-----+-------------------------+\n",
      "|0.0  |(3,[],[])                |\n",
      "|1.0  |(3,[0,1,2],[0.1,0.1,0.1])|\n",
      "|2.0  |(3,[0,1,2],[0.2,0.2,0.2])|\n",
      "|3.0  |(3,[0,1,2],[9.0,9.0,9.0])|\n",
      "|4.0  |(3,[0,1,2],[9.1,9.1,9.1])|\n",
      "|5.0  |(3,[0,1,2],[9.2,9.2,9.2])|\n",
      "+-----+-------------------------+\n",
      "\n",
      "Within Set Sum of Squared Errors = 0.07499999999994544\n",
      "\n",
      "Cluster Centers: \n",
      "[9.1 9.1 9.1]\n",
      "[0.05 0.05 0.05]\n",
      "[0.2 0.2 0.2]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# Loads data.\n",
    "dataset = spark.read.format(\"libsvm\").load(\"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\")\n",
    "dataset.show(truncate=False)\n",
    "\n",
    "# Trains a k-means model.\n",
    "kmeans = KMeans().setK(3).setSeed(1)\n",
    "model = kmeans.fit(dataset)\n",
    "\n",
    "# Evaluate clustering by computing Within Set Sum of Squared Errors.\n",
    "wssse = model.computeCost(dataset)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n",
    "\n",
    "# Shows the result.\n",
    "centers = model.clusterCenters()\n",
    "print(\"\\nCluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
